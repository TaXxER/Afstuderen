%********************************************************************
% Appendix
%*******************************************************
% If problems with the headers: get headings in appendix etc. right
%\markboth{\spacedlowsmallcaps{Appendix}}{\spacedlowsmallcaps{Appendix}}
\chapter{Motivation and Problem Statement}
Ranking is a core problem in the field of information retrieval. The ranking task in information retrieval entails the ranking of candidate documents according to their relevance to a query. Heuristic ranking models have long been around in the information retrieval field. The increasing amounts of potential training data have recently made it possible to leverage machine learning methods to obtain more effective models. Learning-to-Rank is the relatively new research area covering the use of machine learning models for the ranking task.\\

In recent years several Learning-to-Rank benchmark datasets have been proposed that allow us to compare the performance of different Learning-to-Rank methods. Well-known benchmark datasets include the \emph{Yahoo! Learning to Rank Challenge} dataset\cite{Chapelle2011a}, the Yandex Internet Mathematics competition\footnote{http://imat-relpred.yandex.ru/en/}, and the LETOR dataset\cite{Qin2010} that was build by Microsoft Research. One of the concluding observations of the \emph{Yahoo! Learning to Rank Challenge} was that almost all work in the Learning-to-Rank field focuses on ranking accuracy and that efficiency and scalability of Learning-to-Rank algorithms is still an underexposed research area of which its importance is likely to increase in the near future as training sets are becoming larger and larger\cite{Chapelle2011b}. Liu\cite{Liu2007} confirms the observation that efficiency and scalability of Learning-to-Rank methods has so far been an overlooked research area in his influential book on Learning-to-Rank.\\

Some research has been done in the area of on parallel or distributed machine learning \cite{Chu2007,Chang2007}. However, almost none of these studies include the Learning-to-Rank subfield of machine learning. The field of efficient Learning-to-Rank has been getting some attention lately \cite{Asadi2013a,Asadi2013b,Busa-Fekete2012,Sousa2012,Shukla2012} since Chapelle at all \cite{Chapelle2011b} stated its growing importance back in 2011, but only few of these studies \cite{Sousa2012,Shukla2012} have explored the possibilities of efficient Learning-to-Rank through the use of parallel programming paradigms. Lin \cite{Lin2013} observed that algorithms that are of iterative nature, which most Learning-to-Rank algorithms are, are not amenable to the MapReduce framework. Lin argued that as a solution to the non-amenability of iterative algorithms to the MapReduce framework, iterative algorithms can often be replaced with non-iterative alternatives or can still be optimized in such a way that its performance in a MapReduce setting is good enough.\\

The appearance of benchmark datasets gave insight in the performance of different Learning-to-Rank approaches and resulted in increasing popularity of those methods that showed to perform well on one or more benchmark datasets. Up to now it remains unknown whether popular existing Learning-to-Rank methods scale well when they are used in a parallel manner using the MapReduce paradigm.\\

\chapter{Research Goals}
The objective of this thesis is the exploration of execution time speed-up of Learning-to-Rank algorithms through parallelization using the MapReduce paradigm. 
This work focuses on those Learning-to-Rank algorithms that have shown leading performance on relevant benchmark datasets.
The research questions raised and answered in this work include:
\begin{itemize}
\item What is the speed-up of existing Learning-to-Rank algorithms when executed using the MapReduce paradigm?
\item Can we adjust those Learning-to-Rank algorithms such that the parallel execution speed-up increases without decreasing accuracy?
\end{itemize}

\chapter{Approach}
The first research question will be answered by implementing Learning-to-Rank methods in the MapReduce model and measuring the runtime as a factor of the number of cluster nodes used to complete the computation.
To implement the Learning-to-Rank algorithms I will use cloud based MapReduce implementation from Microsoft was used that is called HDInsight, which is based on the popular MapReduce open source implementation Hadoop\footnote{http://hadoop.apache.org/}.
The algorithms that we include in the measurements will be determined based on experimental results on the \emph{Yahoo! Learning to Rank Challenge}\cite{Chapelle2011a}, the Yandex Internet Mathematics competition\footnote{http://imat-relpred.yandex.ru/en/}, the LETOR\cite{Qin2010} dataset and the LETOR successor MSLR-WEB30k.

\chapter{Thesis Overview}

\begin{description}
\item[Part II ]{introduces the reader to the basic principles and recent work in the fields of Learning-to-Rank}
\item[Part III ]{describes a short overview work in the field of parallel machine learning and Learning-to-Rank.}
\item[Part IV ]{describes implementation details of the Learning-to-Rank algorithms in the Hadoop framework.}
\item[Part V ]{presents and discusses speed-up results for the implemented Learning-to-Rank methods.}
\item[Part VI ]{summarizes the results. The limitations of our research as well as future research directions in the field are mentioned here.}
\end{description}