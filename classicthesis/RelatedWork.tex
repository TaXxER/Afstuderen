\chapter{Related Work}
\section{Search characteristics}
The literature research is performed by using the bibliographic databases Scopus and Web of Science with the following search query: \emph{("learning to rank" OR "learning-to-rank" OR "machine learned ranking") AND ("large scale" OR "parallel" OR "distributed")}. An abstract based manual filtering step is applied where I filter those results that actually use the \emph{large scale}, \emph{parallel} or \emph{distributed} terms in context to the \emph{learning to rank}, \emph{learning-to-rank} or \emph{machine learned ranking}. Studies focusing on efficient query evaluation instead of efficient model training are likely to meet all criteria listed. As a last step I will filter out studies focusing on efficient query evaluation.
\subsection{Scopus}
Defined search query resulted in 65 documents.
\subsection{Web of Science}
\section{CCRank}
Wang et al\cite{Wang2011} propose a parallel evolutionary algorithm based on \ac{CC}, a type of evolutionary algorithm. The \ac{CC} algorithm is capable of directly optimizing non-differentiable functions, as \ac{nDCG}, in contrary to many optimization algorithms.  the divide-and-conquer nature of the \ac{CC} algorithm enables parallelisation. CCRank showed an increase in both accuracy and efficiency on the LETOR 4.0 benchmark dataset compared to the baselines. It must be stated however that the increased efficiency was achieved through speed-up and not scale-up. Two reasons have been identified for not achieving linear scale-up with CCRank: 1) parallel execution is suspended after each generation to perform combination in order to produce the candidate solution, 2) Combination has to wait until all parallel tasks have finished, which may spend different running time.
\section{Parallel ListNet using Spark}
Shukla et al\cite{Shukla2012} explored the parallelisation of the well-known ListNet Learning-to-Rank method using Spark. Spark is a parallel computing model that is designed for cyclic data flows which makes it more suitable for iterative algorithms. Spark is incorporated into Hadoop since Hadoop 2.0. The Spark implementation of ListNet showed near a linear training time reduction.