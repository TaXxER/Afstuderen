\chapter{Related Work}
\section{Search characteristics}
The literature research is performed by using the bibliographic databases Scopus and Web of Science with the following search query: \emph{("learning to rank" OR "learning-to-rank" OR "machine learned ranking") AND ("large scale" OR "parallel" OR "distributed")}. An abstract based manual filtering step is applied where I filter those results that actually use the \emph{large scale}, \emph{parallel} or \emph{distributed} terms in context to the \emph{learning to rank}, \emph{learning-to-rank} or \emph{machine learned ranking}. Studies focusing on efficient query evaluation instead of efficient model training are likely to meet all criteria listed. As a last step I will filter out studies focusing on efficient query evaluation.
\subsection{Scopus}
The defined search query resulted in 65 documents.
\subsection{Web of Science}
The defined search query resulted in 16 documents. Three of those documents were also present in the set of 65 documents found using Scopus.
\section{CCRank}
Wang et al\cite{Wang2011a,Wang2011b} propose a parallel evolutionary algorithm based on \ac{CC}, a type of evolutionary algorithm. The \ac{CC} algorithm is capable of directly optimizing non-differentiable functions, as \ac{nDCG}, in contrary to many optimization algorithms.  the divide-and-conquer nature of the \ac{CC} algorithm enables parallelisation. CCRank showed an increase in both accuracy and efficiency on the LETOR 4.0 benchmark dataset compared to the baselines. It must be stated however that the increased efficiency was achieved through speed-up and not scale-up. Two reasons have been identified for not achieving linear scale-up with CCRank: 1) parallel execution is suspended after each generation to perform combination in order to produce the candidate solution, 2) Combination has to wait until all parallel tasks have finished, which may spend different running time.
\section{Parallel ListNet using Spark}
Shukla et al\cite{Shukla2012} explored the parallelisation of the well-known ListNet Learning-to-Rank method using Spark. Spark is a parallel computing model that is designed for cyclic data flows which makes it more suitable for iterative algorithms. Spark is incorporated into Hadoop since Hadoop 2.0. The Spark implementation of ListNet showed near a linear training time reduction.
\section{Gradient Boosted Distributed Decision Trees}
Ye et al\cite{Ye2009} described how to implement the \ac{GBDT} process in a parallel manner using both MPI and Hadoop. \ac{GBDT}'s are shown to be able to achieve good accuracy in a Learning-to-Rank setting when used in a pairwise\cite{Zheng2007} or listwise\cite{Wang2011} setting. Experiments showed the Hadoop implementation to result into too expensive communication cost to be useful. Authors believed that these high communication costs were a result of the communication intensive implementation that was not well suited for the MapReduce paradigm. The MPI approach proved to be successful and obtained near linear speed-ups.
\section{nDCG-Annealing}
Karimzadeghan el al\cite{Karimzadehgan2011} proposed a method using Simulated Annealing along with the Simplex method for its parameter search. This method directly optimises the often non-differentiable Learning-to-Rank evaluation metrics like \ac{nDCG} and \ac{MAP}. The authors successfully parallelised their method in the MapReduce paradigm using Hadoop. The approach showed to be effective on both the LETOR 3.0 dataset and their own dataset with contextual advertising data. Unfortunately their work does not directly report on the speed-up obtained by parallelising  with Hadoop, but it is mentioned that further work needs to be done to effectively leverage parallel execution.
\section{Low complexity Learning-to-Rank}
Designing Learning-to-Rank algorithms with low time complexity for training is a different another approach towards large scale Learning-to-Rank. Pahikkala et al\cite{Pahikkala2009} describe a pairwise \ac{RLS} type of ranking function, RankRLS, with time complexity $\mathcal{O}(n^3+n^2m)$, with $n$ the number of features and $m$ the number of training documents. The RankRLS ranking function showed ranking performance similar to RankSVM on the BioInfer corpus\cite{Pyysalo2007}, a corpus for information extraction in the biomedical domain.
\section{Distributed Stochastic Gradient Descent}
Long et al\cite{Long2012} describe special case of their pairwise cross-domain factor Learning-to-Rank method using distributed optimization of \ac{SGD} based on Hadoop MapReduce. Parallelisation of the \ac{SGD} optimization algorithm was performed using the MapReduce based method described by  Zinkevich et al\cite{Zinkevich2010} has been used. Real world data from Yahoo! has been used to show that the model is effective. Unfortunately the speed-up obtained by training their model in parallel is not reported.
\section{FPGA-based LambdaRank}
Yan et al\cite{Yan2009,Yan2010,Yan2011,Yan2012} described the development and incremental improvement of a \ac{SIMD} architecture \ac{FPGA} designed to run the Neural Network based LambdaRank Learning-to-Rank algorithm. This architecture achieved a 29.3X speed-up compared to the software implementation when evaluated on data from a commercial search engine. The exploration of \ac{FPGA} for Learning-to-Rank showed other advantages of the \ac{FPGA} approach next to faster model training. In their latest publication\cite{Yan2012} the FPGA based LambdaRank implementation showed it could achieve up to 19.52X power efficiency and 7.17X price efficiency for query processing compared to Intel Xeon servers currently used at the commercial search engine.