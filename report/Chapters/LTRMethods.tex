Algorithms and details of the well-performing Learning-to-Rank methods as selected in the afore-going part are presented and explained in this part.

\section{ListNet}
ListNet \cite{Cao2007} is a listwise ranking function whose loss function is not directly related to information retrieval evaluation metrics. ListNet's loss function is defined using a probability distribution on permutations. Probability distributions on permutations have been a research topic within the field of probability theory and has been extensively researched. One of the most well-known permutation probability distributions in the field, the Plackett-Luce model \cite{Plackett1975,Luce1959}, is used in ListNet. The Plackett-Luce model defines the probability of all possible permutations $\pi$, given all document ranking scores $S$, as shown in Equation \ref{eq:plackett_luce}.
\begin{equation}
P(\pi|S) = \prod\limits_{j=1}^{m}\frac{\phi(s_{\pi^{-1}(j)})}{\sum\nolimits_{u=1}^{m}\phi(s_{\pi^{-1}(u)})}
\label{eq:plackett_luce}
\end{equation}
ListNet uses Gradient Descent to optimise neural network such that its Cross Entropy loss compared to the Plackett-Luce distribution over the ground truth is minimal. Note that some sources, including Liu \cite{Liu2007}, describe ListNet as using KL divergence as loss function. KL divergence and Cross-entropy are however identical up to an additive constant when comparing distribution $q$ against a fixed reference distribution $p$, since the cross-entropy definition can be formulated as in Equation \ref{eq:cross_entropy}.
\begin{equation}
H(p,q) = H(p) + D_{KL}(p||q)
\label{eq:cross_entropy}
\end{equation}
where $H(p)$ is the entropy of $p$ and $D_{KL}(p||q)$ is the Kullback-Leibler divergence of $q$ from $p$.\\

\noindent Equation \ref{eq:gradient_descent} describes the gradient descent step to minimise loss function $L(y^{(i)},z^{(i)}(f_\omega))$ with respect to parameter $\omega$. 
\begin{equation}
\Delta\omega = \frac{\partial L(y^{(i)},z^{(i)}(f_\omega))}{\partial \omega} = - \sum_{\forall g \in \mathscr{G}_k}\limits\frac{\partial P_{z^{(i)}(f_\omega)}(g)}{\partial \omega}\frac{P_{y^{(i)}}(g)}{P_{z^{(i)}(f_\omega)}(g)}
\label{eq:gradient_descent}
\end{equation}

\noindent Algorithm \ref{alg:listnet} shows the pseudo-code of the ListNet training phase.\\
\LinesNumbered
\begin{algorithm}[H]
 \KwData{training data \{$(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})$\}}
 \KwIn{number of iterations $T$ and learning rate $\eta$}
 Initialize parameter $\omega$\\
 \For{$t\leftarrow 1$ \KwTo $T$}{
 	\For{$i\leftarrow 1$ \KwTo $m$}{
 		Input $x^{(i)}$ of query $q^{(i)}$ to Neural Network and compute score list $z^{(i)}(f_\omega)$ with current $\omega$.\\
 		Compute gradient $\Delta\omega$ using Eq. (\ref{eq:gradient_descent}).\\
 		Update $\omega = \omega - \eta \times \Delta\omega$.
 	}
 }
 Output Neural Network model $\omega$.
 \caption{Learning algorithm of ListNet, obtained from \cite{Cao2007}}
 \label{alg:listnet}
\end{algorithm}

\section{SmoothRank}
SmoothRank \cite{Chapelle2010} is a listwise ranking method that directly optimises an information retrieval evaluation measure by smoothing, that is, approximating the rank position. In this section I will use \ac{nDCG} for illustration of SmoothRank, but the same procedure can also be applied to \ac{MAP} or any other information retrieval measure. The smoothing function used in SmoothRank based on the softmax activation function \cite{Bridle1990} that is often used in neural networks, which is formally defined as shown in Equation \ref{eq:softmax_algorithm}.
\begin{equation}
p_i = \frac{e^{f_i/\sigma}}{\sum\nolimits_{j=1}^{m}e^{f_j/\sigma}}
\label{eq:softmax_algorithm}
\end{equation}

where $\sigma$ is the smoothing parameter. Chapelle et al \cite{Chapelle2010} apply the softmax activation function to the \ac{nDCG} formula and thereby introduce a soft version of indicator variable $h_{i,j}$ as formulated in Equation \ref{eq:soft_ndcg}.

\begin{equation}
h_{i,j} = e^{-\frac{(f(x_i))-(f(x_{d(j)}))^2}{\sigma}}\Big/\sum\nolimits_{k=1}^{m}e^{-\frac{(f(x_k))-f(x_{d(j)})^2}{\sigma}}
\label{eq:soft_ndcg}
\end{equation}

It can be shown that the derivative of the smoothed \ac{nDCG} version shown in Equation \ref{eq:soft_ndcg} and the smoothed versions of other \ac{IR} metrics can be calculated in $\mathcal{O}(m^2)$, which enable fast gradient descent optimisation. The optimisation step in SmoothRank uses the nonlinear conjugate gradient method  with Polak-Ribiere update \cite{Shewchuk1994}, which is a type of gradient descent method. The optimisation method is prone to local optima, which is alleviated by adding a good starting point and regulariser.\\

The starting point in SmoothRank is set to either the solution of a simple linear regression, or alternatively to the solution of Rank\acs{SVM}. Since this starting point is expected to already be a good solution, a regulariser term is added to the SmoothRank objective function to prevent the solution from deviating to much from the starting point. The regularised smooth objective function is formulated as $\lambda||w-w_0||^2$ where $\lambda$ is a hyperparameter tuned on the validation set, and $w_0$ is the starting point solution.\\

The choice of the smoothing parameter $\sigma$ in Equation \ref{eq:soft_ndcg} is important, because a too small value makes the function more non-smooth and therefore harder to optimise, while a too large value results in a optimisation function that substantially differs from the optimal rankings. SmoothRank uses an annealing method where the optimisation procedure starts with a large $\sigma$ and iteratively reduces it by dividing it by 2 at each step. Algorithm \ref{alg:smoothrank} shows the algorithm that summarises all steps of the SmoothRank method.

\LinesNumbered
\begin{algorithm}[H]
 Find an initial solution $w_0$ (by regression of Rank\acs{SVM}).\\
 Set $w = w_0$ and $\sigma$ to a large value.\\
 \While{Stopping condition not satisfied}{
 	 Starting from $w$, minimize by non-linear conjugate gradient descent:
 	 $\lambda||w-w_0||^2 - \sum\nolimits_{q}A_q(w,\sigma)$\\
 	 $\sigma = \sigma/2$
 }
 \caption{Learning algorithm of SmoothRank, obtained from \cite{Chapelle2010}}
 \label{alg:smoothrank}
\end{algorithm}

\section{FenchelRank}

\section{FSMRank}

\section{LRUF}