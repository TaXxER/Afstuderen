Algorithms and details of the well-performing Learning-to-Rank methods as selected in the afore-going part are presented and explained in this part.

\section{ListNet}
ListNet \cite{Cao2007} is a listwise ranking function whose loss function is not directly related to information retrieval evaluation metrics. ListNet's loss function is defined using a probability distribution on permutations. Probability distributions on permutations have been a research topic within the field of probability theory and has been extensively researched. One of the most well-known permutation probability distributions in the field, the Plackett-Luce model \cite{Plackett1975,Luce1959}, is used in ListNet. The Plackett-Luce model defines the probability of all possible permutations $\pi$, given all document ranking scores $S$, as shown in Equation \ref{eq:plackett_luce}.
\begin{equation}
P(\pi|S) = \prod\limits_{j=1}^{m}\frac{\phi(s_{\pi^{-1}(j)})}{\sum\nolimits_{u=1}^{m}\phi(s_{\pi^{-1}(u)})}
\label{eq:plackett_luce}
\end{equation}
ListNet uses Gradient Descent to optimise neural network such that its Cross Entropy loss compared to the Plackett-Luce distribution over the ground truth is minimal. Note that some sources, including Liu \cite{Liu2007}, describe ListNet as using KL divergence as loss function. KL divergence and Cross-entropy are however identical up to an additive constant when comparing distribution $q$ against a fixed reference distribution $p$, since the cross-entropy definition can be formulated as in Equation \ref{eq:cross_entropy}.
\begin{equation}
H(p,q) = H(p) + D_{KL}(p||q)
\label{eq:cross_entropy}
\end{equation}
where $H(p)$ is the entropy of $p$ and $D_{KL}(p||q)$ is the Kullback-Leibler divergence of $q$ from $p$.\\

\noindent Equation \ref{eq:gradient_descent} describes the gradient descent step to minimise loss function $L(y^{(i)},z^{(i)}(f_\omega))$ with respect to parameter $\omega$. 
\begin{equation}
\Delta\omega = \frac{\partial L(y^{(i)},z^{(i)}(f_\omega))}{\partial \omega} = - \sum_{\forall g \in \mathscr{G}_k}\limits\frac{\partial P_{z^{(i)}(f_\omega)}(g)}{\partial \omega}\frac{P_{y^{(i)}}(g)}{P_{z^{(i)}(f_\omega)}(g)}
\label{eq:gradient_descent}
\end{equation}

\noindent Algorithm \ref{alg:listnet} shows the pseudo-code of the ListNet training phase.\\
\LinesNumbered
\begin{algorithm}[H]
 \KwData{training data \{$(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})$\}}
 \KwIn{number of iterations $T$ and learning rate $\eta$}
 Initialize parameter $\omega$\\
 \For{$t\leftarrow 1$ \KwTo $T$}{
 	\For{$i\leftarrow 1$ \KwTo $m$}{
 		Input $x^{(i)}$ of query $q^{(i)}$ to Neural Network and compute score list $z^{(i)}(f_\omega)$ with current $\omega$.\\
 		Compute gradient $\Delta\omega$ using Eq. (\ref{eq:gradient_descent}).\\
 		Update $\omega = \omega - \eta \times \Delta\omega$.
 	}
 }
 Output Neural Network model $\omega$.
 \caption{Learning algorithm of ListNet, obtained from \cite{Cao2007}}
 \label{alg:listnet}
\end{algorithm}

\section{SmoothRank}
SmoothRank \cite{Chapelle2010} is a listwise ranking method that directly optimises an information retrieval evaluation measure by smoothing, that is, approximating the rank position. In this section I will use \ac{nDCG} for illustration of SmoothRank, but the same procedure can also be applied to \ac{MAP} or any other information retrieval measure. The smoothing function used in SmoothRank based on the softmax activation function \cite{Bridle1990} that is often used in neural networks, which is formally defined as shown in Equation \ref{eq:softmax_algorithm}.
\begin{equation}
p_i = \frac{e^{f_i/\sigma}}{\sum\nolimits_{j=1}^{m}e^{f_j/\sigma}}
\label{eq:softmax_algorithm}
\end{equation}

where $\sigma$ is the smoothing parameter. Chapelle et al \cite{Chapelle2010} apply the softmax activation function to the \ac{nDCG} formula and thereby introduce a soft version of indicator variable $h_{i,j}$ as formulated in Equation \ref{eq:soft_ndcg}.

\begin{equation}
h_{i,j} = e^{-\frac{(f(x_i))-(f(x_{d(j)}))^2}{\sigma}}\Big/\sum\nolimits_{k=1}^{m}e^{-\frac{(f(x_k))-f(x_{d(j)})^2}{\sigma}}
\label{eq:soft_ndcg}
\end{equation}

It can be shown that the derivative of the smoothed \ac{nDCG} version shown in Equation \ref{eq:soft_ndcg} and the smoothed versions of other \ac{IR} metrics can be calculated in $\mathcal{O}(m^2)$, which enable fast gradient descent optimisation. The optimisation step in SmoothRank uses the nonlinear conjugate gradient method  with Polak-Ribiere update \cite{Shewchuk1994}, which is a type of gradient descent method. The optimisation method is prone to local optima, which is alleviated by adding a good starting point and regulariser.\\

The starting point in SmoothRank is set to either the solution of a simple linear regression, or alternatively to the solution of Rank\acs{SVM}. Since this starting point is expected to already be a good solution, a regulariser term is added to the SmoothRank objective function to prevent the solution from deviating to much from the starting point. The regularised smooth objective function is formulated as $\lambda||w-w_0||^2$ where $\lambda$ is a hyperparameter tuned on the validation set, and $w_0$ is the starting point solution.\\

The choice of the smoothing parameter $\sigma$ in Equation \ref{eq:soft_ndcg} is important, because a too small value makes the function more non-smooth and therefore harder to optimise, while a too large value results in a optimisation function that substantially differs from the optimal rankings. SmoothRank uses an annealing method where the optimisation procedure starts with a large $\sigma$ and iteratively reduces it by dividing it by 2 at each step. Algorithm \ref{alg:smoothrank} shows the algorithm that summarises all steps of the SmoothRank method.\\
\LinesNumbered
\begin{algorithm}[H]
 Find an initial solution $w_0$ (by regression of Rank\acs{SVM}).\\
 Set $w = w_0$ and $\sigma$ to a large value.\\
 \While{Stopping condition not satisfied}{
 	 Starting from $w$, minimize by non-linear conjugate gradient descent:
 	 $\lambda||w-w_0||^2 - \sum\nolimits_{q}A_q(w,\sigma)$\\
 	 $\sigma = \sigma/2$
 }
 \caption{Learning algorithm of SmoothRank, obtained from \cite{Chapelle2010}}
 \label{alg:smoothrank}
\end{algorithm}

\section{FenchelRank}
FenchelRank \cite{Lai2013} learning method that addresses the sparse Learning-to-Rank problem, which is the problem of learning a ranking function with only a few non-zero coefficients with respect to the input features. FenchelRank is based on the theory of Fenchel Duality \cite{Rifkin2007} and uses the genetic algorithm framework proposed by Shalev-Shwartz and Singer \cite{Shalev-Shwartz2010}.

FenchelRank optimises the objective function shown in Equation \ref{eq:pairwise_l1_loss} that is equivalent to the standard $\ell_1$-norm regularised pairwise loss function.

\begin{equation}
\min_w G(w) = \min_w I_{||w||_{1} \le 1}(w) + \frac{r^2}{p} \sum\limits_{i=1}^{p}\max(0,\frac{1}{r}-(Kw)_i)^2
\label{eq:pairwise_l1_loss}
\end{equation}

The objective function in Equation \ref{eq:pairwise_l1_loss} is not differentiable everywhere because of its $\ell_1$-norm regularisation term.

Let $D(w) = -G(w)$, then the objective function stated in \ref{eq:pairwise_l1_loss} can be rewritten as shown in Equation \ref{eq:fenchel_dual}.
\begin{equation}
\max_w D(w) = \max_w I_{||w||_{1} \le 1}(w) - \frac{r^2}{p} \sum\limits_{i=1}^{p}\max(0,\frac{1}{r}-(Kw)_i)^2
\label{eq:fenchel_dual}
\end{equation}


\LinesNumbered
\begin{algorithm}[H]
 \KwData{pairwise training data matrix $K$}
 \KwIn{desired accuracy $\epsilon$, maximum number of iterations $T$ and the radius $r$ of the $\ell1$ ball.}
 Initialize: $w_1$ = $0_m$\\
 \For{$t\leftarrow 1$ \KwTo $T$}{
 	//check if the early stopping criterion is satisfied\\
 	\If{$||g_{t}||_{\infty} + \langle d_{t}, -Kw_{t} \rangle \le \epsilon$}{
 	// Here $d_{t} = \nabla f^{*}(-Kw_{t}) = \frac{\partial f^{*}(-Kw)}{\partial(Kw)}|w=w_{t}$ and $g_{t} = d_{t}^{T}K$\\
 	return $w_{t}$ as ranking predictor $w$
 	}
 //greedily choose a feature to update\\
 Choose $j_{t} = \argmax_{j}|(g_t)_j)|$\\
 //compute an appropriate step size\\
 Let $\mu_t = \argmax_{0 \le \mu_{t} \le 1} D((1-\mu_{t})w_{t} + \mu_{t}\sign((g_{t})_{j_{t}})e^{j_{t}})$\\
 //update the model with the chosen feature and step size\\
 Update $w_{t+1}=(1-\mu_{t})w_{t} + \mu_{t}\sign((g_{t})j_{t})e^{j_{t}}$
 }
 return $w_{T}$ as ranking predictor for $w$
 \caption{Learning algorithm of FenchelRank, obtained from \cite{Lai2013}}
 \label{alg:fenchelrank}
\end{algorithm}
\section{FSMRank}

\section{LRUF}
Learning automaton.