\label{chap:implementation}
The first section of this chapter will briefly discuss the HDInsight platform, the Hadoop ecosystem components offered by HDInsight and, in this regard, the Hadoop components used for implementation of the algorithms described in Chapter \ref{chap:ltr_methods}. The second section of this chapter describes a Java framework that handles the joint components needed for MapReduce Learning to Rank computation, independent of the Learning to Rank model. The subsequent sections report the implementation details of specific Learning to Rank models.

\section{Architecture}
Ranking algorithms consist of a sequence of operations on the input data which are often of iterative nature. Apache Pig \cite{Olston2008} is used to implement the sequence of operations on the input data. Pig Latin is the data processing language that runs on Apache Pig. It was designed based on the observation that the traditional MapReduce paradigm is too low-level and rigid, and holds the middle between the declarative style of SQL and the procedural style of MapReduce. The Apache Pig system translates Pig Latin into MapReduce plans that are executed on Hadoop. The choice to implement the Learning to Rank algorithms in Pig Latin allows for more focus on the data operations and less focus on low-level implementation details, as compared to native Hadoop MapReduce. Furthermore, it allows us to rely on Apache Pig to create efficient MapReduce plans out of the Pig Latin code and therefore lowers the implementation-dependent factor of the experiments.\\

\subsection{The HDInsight Platform}
Azure HDInsight supports the traditional \ac{HDFS} as described by Shvacko et al. \cite{Shvachko2010}, as well as Microsoft's own storage solution \ac{WASB}. Blob storage decouples the storage from the HDInsight Hadoop cluster; it enables safe deletion of a HDInsight cluster without losing data, as data is not solely stored on the cluster itself, but also on a separate storage that is not cluster-dependent. Azure \ac{WASB} storage allows the user to select one of Microsoft's data centres for storage. \ac{WASB} storage in the West Europe region (located in Amsterdam) is used for storage, as this data centre is located close to where the experiments are executed.\\

Microsoft offers a scalable and on-demand Hadoop service with HDInsight, which enables Hadoop services for those not able to make the required investments for their own cluster. The latest HDInsight version available at the time of writing, HDInsight 3.1, runs the Hortonworks distribution of Hadoop version 2.4. While early versions of Hadoop were merely an open source implementation of MapReduce, newer versions since Hadoop 2.0 offer support for variety of programming models with the introduction of Hadoop YARN \cite{Vavilapalli2013}. HDInsight Hadoop data nodes are regular Large A3 Microsoft Azure virtual machines with four core processors and 7GB RAM. Newly supported programming models since Hadoop 2.0 include Dryad \cite{Isard2007}, Giraph \cite{Avery2011}, MPI, REEF \cite{Chun2013}, Spark \cite{Zaharia2010}, and Storm \cite{Aniello2013}. Even though these programming models are now supported by Hadoop and some of these programming models have recently increased in popularity, they still lack the critical mass as the data processing framework of choice that MapReduce has as Lin argued back in 2012 \cite{Lin2013}(see section \ref{sec:motivation}). Therefore, even though some of these programming models might be a better fit for iterative algorithms, we use Hadoop MapReduce of the programming model to implement the Learning to Rank algorithms.\\

HDInsight 3.1 offers multiple ways of submitting Hadoop jobs to a HDInsight cluster, which are described in Table \ref{tbl:hdinsight_endpoints}. Similar to \ac{WASB} storage, one of the Microsoft data centres can be chosen to host the Hadoop cluster when a HDInsight cluster is created. To guarantee proximity between storage and cluster, the West Europe data centre in Amsterdam is used as cluster location.\\

\begin{table}
\centering
\begin{tabular}{p{4.2cm}p{2.6cm}p{5.5cm}}\toprule
Job submission method & Type & Description \\
\midrule
Powershell & Powershell scripts & The Azure module for Windows PowerShell enables direct submission of Hadoop jobs through PowerShell cmdlets.\\
C\# API & C\# API & A wrapper API is offered to submit Hadoop MapReduce jobs directly from C\# code.\\
HiveServer/HiveServer2 & REST endpoint & Apache Hive \cite{Thusoo2009} is an open-source data warehousing solution on top of Hadoop, that supports processing of a SQL-like declarative language called HiveQL. HiveServer and its successor HiveServer 2 are REST endpoints that allow remote submission of HiveQL queries.\\
Oozie & REST endpoint & Apache Oozie \cite{Islam2012} is a workflow scheduler to manage Apache Hadoop jobs. Oozie enables users to specify Directed Acyclical Graphs of action, where each action is specified in either MapReduce or Pig.\\
WebHCat/Templeton & REST endpoint & WebHCat, formerly known as Templeton, is a REST API for HCatalog, a table and storage management layer for Hadoop. WebHCat allows users to use either Apache Pig, Apache MapReduce or Apache Hive for data processing.\\	
\bottomrule
\end{tabular}
\caption{HDInsight REST endpoints for job submission}
\label{tbl:hdinsight_endpoints}
\end{table}

\subsection{Framework description}
Fold handling in the context of a cross-validation experiment is the process of loading the correct data folds for training, validation and testing in the multiple rounds that form the cross-validation experiment. Fold handling is a task that needs to be taken care of independent of the ranking model that is being evaluated. Given that most ranking models are of an iterative nature, the task of iteration handling is also a task that need to be performed independent of the ranking model. Iteration handling and fold handling are procedures in which the same steps are repeated for each iteration or cross-validation round respectively. Pig Latin, in contrast to more procedural MapReduce-job-generating languages like Sawzall \cite{Pike2005}, has no support for loops, which are needed to perform iteration handling and fold handling. Since iteration handling and fold handling are tasks that need to be addressed for each ranking model and that cannot be solved with Pig, we create a framework that takes care of both iteration and fold handling and generates the Pig Latin code for the current iteration and fold.\\

Learning to Rank algorithms are likely to consist of multiple loops over the input data per iteration of the algorithm, and consequently multiple Pig jobs will be needed per iteration of the algorithm. An example of this is a Pig implementation of gradient descent, where a first Pig job might calculate gradients and writes them to storage, after which the framework assists in reading the gradients from storage and allows them to be used as input parameters of a second Pig job that calculates new feature weights based on its gradient parameter and a predetermined step size. Handling communication between Pig jobs within a single iteration of a Learning to Rank algorithm is not trivial. A Pig Job, after completion, writes its result to \ac{WASB} storage, while this result is needed by a subsequent Pig job as parameter. The framework enables reading the result of a Pig job from \ac{WASB} storage which can then be used as parameter within a subsequent Pig job. \\

The aim of this framework is to let implementations of ranking models focus solely on implementing the sequential steps of one iteration of the algorithm, while the framework handles that 1) these sequential steps are performed iteratively, 2) these sequential steps are performed on the multiple training folds of data and 3) data can be passed from one Pig job within the algorithm to another Pig job. This framework that handles folding and iterations will be implemented in Java and will work such that fold- and iteration dependent parts of the Pig code will be generated dynamically by the Java framework after which the Pig job will be sent to the cluster.\\

Oozie and WebHCat/Templeton are the two methods for job submission in Table \ref{tbl:hdinsight_endpoints} that both 1) support Apache Pig jobs, and 2) Can be used from within Java code. Table \ref{tbl:oozie_templeton} shows the necessary procedures for job submission from Oozie as well as from WebHCat will be sketched. Table \ref{tbl:oozie_templeton} shows Oozie job submission to be more complex for the case of dynamically generated jobs than WebHCat/Templeton. Oozie is more fitting for static Hadoop jobs that require a workflow consisting of a sequence of Pig and MapReduce jobs mixed together, but is a lesser fit for our situation. Templeton will be used for submission of the Pig jobs, as the HDInsight version that was available at the start of the implementation did not yet support WebHCat.\\

\begin{table}
\centering
\begin{tabular}{p{5cm}p{5cm}}\toprule
Job submission procedure for Apache Oozie & Job submission procedure for WebHCat/Templeton \\
\midrule
1. Let the framework build the Pig job dynamically. & 1. Let the framework build the Pig job dynamically.\\
2. Encapsulate the Pig job in an Oozie workflow. & 2. Submit the Pig job through the WebHCat/Templeton REST API.\\
3. Upload the Oozie workflow to HDFS storage. & \\
4. Execute the Oozie workflow through the Oozie REST API. & \\
\bottomrule
\end{tabular}
\caption{Comparison of Oozie and WebHCat job submission procedures}
\label{tbl:oozie_templeton}
\end{table}

We create a utility class HDInsightWrapper, which abstracts away connection setup, authorisation and response parsing from the tasks of submitting jobs to the cluster and retrieving data from \ac{WASB} storage. The HDInsightWrapper class is parametrised with connection details like the cluster name, cluster user, cluster password, storage account, storage container and storage key, and has two methods:

\begin{description}
\item[void runPig(String pigCode)]{Receives a Pig script in String format as input and handles the submission of this script as MapReduce job on the cluster. Polls the Templeton REST API with progress requests every 50 milliseconds until the MapReduce job has completed. Blocks until the MapReduce job has completed.}
\item[String runPig(String pigCode, String outputDir)]{Identical to runPig(String pigCode), but reads the result of the computation from location 'outputDir' after completion of the MapReduce job and outputs the result as String value.}
\end{description}

Setting the degree of parallelisation is crucial to obtain optimal cluster utilisation. HDInsight cluster machines offer four mapper slots and two reducer slots per data node. Cluster utilisation is optimal when the computational work is evenly distributed over exactly the number of available mappers in the map phase, and evenly distributed over exactly the number of reducers in the reduce phase. The number of mappers used can be controlled by setting MapReduce configuration parameters mapreduce.input.fileinputformat.split.maxsize, mapreduce.input.fileinputformat.split.minsize, and the Pig configuration parameter pig.maxCombinedSplitSize to the data size in bytes of the input training data divided by the number of available mappers. To control the number of used reducers, Pig offers two options: 1) the default\_parallel parameters, which can set a default number of reducers used throughout all MapReduce jobs that the Pig script consists of, and 2) the "PARALLEL" clause, which sets the number of reducers at operator level (overrides default\_parallel if set). The framework uses listed configuration parameters to control the numbers of mappers used and uses the "PARALLEL" clause to set the number of used reducers. Pig code to set the number of mappers and reducers are dynamically set by the framework such that the optimal number of mappers and reducers are used.

\section{ListNet}
The following sections describe the Pig jobs that jointly form the three independent parts of the ListNet ranking model: 1) Preprocessing, 2) Training (this includes evaluation over the validation set) and 3) Testing (evaluation over the test set). 
\subsection{Preprocessing}
The preprocessing phase consists of two separate Pig jobs. The first Pig job determines the minimum and the maximum values per feature in the training set. The second Pig job rescales each feature of the train, validation and test data sets using the following formula for rescaling:
\begin{equation}
x^{'} = \frac{x-min(x)}{max(x)-min(x)}
\label{eq:rescaling}
\end{equation}
This rescaling procedure sets the values of all features to be within range $[0,1]$.\\

The first Pig job:\\
\begin{minipage}{\linewidth}
\begin{lstlisting}
REGISTER [path prefix]/lib/*.jar;
TRAIN = LOAD '[path prefix]/input/[data set name]/Fold[fold number]/train.txt' USING PigStorage(' ');
TRAIN_STD = FOREACH TRAIN GENERATE flatten(udf.util.ToStandardForm(*));
TRAIN_STD_BY_QUERY = GROUP TRAIN_STD BY $1 PARALLEL [available reducers];
MIN_MAX = FOREACH TRAIN_STD_BY_QUERY GENERATE flatten(udf.util.GetMinMax(*));
MIN_MAX_GRPD = GROUP MIN_MAX ALL;
MIN_MAX_FIN = FOREACH MIN_MAX_GRPD GENERATE flatten(udf.util.CombineMinMax(*));
STORE MIN_MAX_FIN INTO 'minmax[fold number]';
\end{lstlisting}
\end{minipage}\\
All expressions between square brackets in the code snippet above are dynamically set by the framework. The minimum and maximum values per feature stored in MIN\_MAX\_FIN are read from storage by the framework after completion of the MapReduce job. The framework passes these minimum and maximum values to the second Pig job by passing an array of minimum and maximum values to the constructor of the udf.util.ScaleFeatures() \ac{UDF}, that performs the rescaling operation of Equation \ref{eq:rescaling}s.\\

\begin{table}
\centering
\begin{tabular}{p{6cm}p{7cm}}\toprule
UDF & Description \\
\midrule
udf.util.ToStandardForm() & Transforms the data set into the standard form of relevance label in first column followed by feature values. Strips data of any other columns, if present.\\
udf.util.GetMinMax() & Extracts the minimum and maximum value per feature, for the documents of a single query.\\
udf.util.CombineMinMax() & Combines outputs of the udf.util.GetMinMax() UDF for each query into globally minimum and maximum feature values.\\
\bottomrule
\end{tabular}
\caption{Description of preprocessing phase User Defined Functions (Pig job 1)}
\label{tbl:preprocessing_udfs_1}
\end{table}

The second Pig job:\\
\begin{minipage}{\linewidth}
\begin{lstlisting}
REGISTER [path prefix]/lib/*.jar;
TRAIN = LOAD '[path prefix]/input/[data set name]/Fold[fold number]/train.txt' USING PigStorage(' ');
VALIDATE = LOAD '[path prefix]/input/[data set name]/Fold[fold number]/vali.txt' USING PigStorage(' ');
TEST = LOAD '[path prefix]/input/[data set name]/Fold[fold number]/test.txt' USING PigStorage(' ');
TRAIN_STD = FOREACH TRAIN GENERATE flatten(udf.util.ToStandardForm(*));
VALIDATE_STD = FOREACH VALIDATE GENERATE flatten(udf.util.ToStandardForm(*));
TEST_STD = FOREACH TEST GENERATE flatten(udf.util.ToStandardForm(*));
DEFINE ScaleFeatures udf.util.ScaleFeatures('[array with minimum and maximum feature values]');
TRAIN_SCA = FOREACH TRAIN_STD GENERATE flatten(ScaleFeatures(*));
VALIDATE_SCA = FOREACH VALIDATE_STD GENERATE flatten(ScaleFeatures(*));
TEST_SCA = FOREACH TEST_STD GENERATE flatten(ScaleFeatures(*));
STORE TRAIN_SCA INTO 'train_sca[fold number]' USING BinStorage();
STORE VALIDATE_SCA INTO 'validate_sca[fold number]' USING BinStorage();
STORE TEST_SCA INTO 'test_sca[fold number]' USING BinStorage();
\end{lstlisting}
\end{minipage}\\

\begin{table}
\centering
\begin{tabular}{p{5cm}p{8cm}}\toprule
UDF & Description \\
\midrule
udf.util.ToStandardForm() & See Table \ref{tbl:preprocessing_udfs_1} for description.\\
udf.util.ScaleFeatures() & Uses the minimum and maximum feature values with which it is parametrised perform the following rescaling transformation to the features: $x^{'} = \frac{x-min(x)}{max(x)-min(x)}$.\\
\bottomrule
\end{tabular}
\caption{Description of preprocessing phase User Defined Functions (Pig job 2)}
\label{tbl:preprocessing_udfs_2}
\end{table}

\subsection{Training}
The Pig jobs that form the ListNet training phase form an implementation of the theoretical description of ListNet as described in section \ref{sec:ltrmethods_listnet}. The training stage, like the preprocessing stage, consists of two separate Pig jobs. The first Pig job calculates the Cross Entropy loss on training data of the current model and calculates the gradients for the next model update. The second Pig job is an internal validation step that validates the model on the validation set by calculating \ac{NDCG}@k.\\

The first Pig job:\\
\begin{minipage}{\linewidth}
\begin{lstlisting}
REGISTER [path prefix]/lib/*.jar;
DEFINE QueryLossGradient udf.listnet.QueryLossGradient('[feature dimensionality of data set]');
DEFINE ExpRelOurScores udf.listnet.ExpRelOurScores('[neural network weights & iteration number]');
[FIRST TRAINING ITERATION:]
	TRAIN_SCA = LOAD 'train_sca[fold number]/*' USING BinStorage();
	TR_BY_QUERY = GROUP TRAIN_SCA BY $1 PARALLEL [number of avaiable reducers];
	TR_EXP_REL_SCORES = FOREACH TR_BY_QUERY GENERATE flatten(ExpRelOurScores(TRAIN_SCA));
	STORE TR_EXP_REL_SCORES INTO 'tr_exp_rel_scores-f[fold number]' USING BinStorage();
[SUBSEQUENT TRAINING ITERATIONS:]
	TR_EXP_REL_SCORES = LOAD 'tr_exp_rel_scores-f[fold number]/*' USING BinStorage();
	TR_EXP_REL_SCORES = FOREACH TR_EXP_REL_SCORES GENERATE flatten(ExpRelOurScores(*)) PARALLEL [number of available reducers];
TR_QUERY_LOSS_GRADIENT = FOREACH TR_EXP_REL_SCORES GENERATE flatten(QueryLossGradient(*)) PARALLEL [number of available reducers];
TR_QUERY_LOSS_GRADIENT_GRPD = GROUP TR_QUERY_LOSS_GRADIENT ALL;
TR_LOSS_GRADIENT = FOREACH TR_QUERY_LOSS_GRADIENT_GRPD GENERATE flatten(udf.listnet.MultiSum(*));
STORE TR_LOSS_GRADIENT INTO 'tr_loss_gradient-f[fold number]i[iteration number]';
\end{lstlisting}
\end{minipage}\\

The actual neural network weights, passed by the framework as constructor parameter in the script above, are administered in Java code. The per-feature gradients calculated by the Pig job above are read from storage after completion and used to update the neural network by, for each feature, adding the feature gradient multiplied with a step size parameter to the previous feature weight.

\begin{table}
\centering
\begin{tabular}{p{6cm}p{7cm}}\toprule
UDF & Description \\
\midrule
udf.listnet.QueryLossGradient() & Calculates the Cross Entropy loss for a query and calculates the gradients per feature based on this query.\\
udf.listnet.ExpRelOurScores() & Calculates the predicted relevance label of a query based on the current model weights and transforms this following the transformation $x \rightarrow e^{x}$. In case the current iteration is the first iteration, the same transformation is applied to the ground truth relevance label.\\
udf.listnet.MultiSum() & Calculates aggregated loss and feature gradients by summing the per-query losses and per-query feature gradients.\\
\bottomrule
\end{tabular}
\caption{Description of training phase User Defined Functions (Pig job 1)}
\label{tbl:training_udfs_1}
\end{table}

The second Pig job of the training stage validates the performance of the model weights that were trained in the first Pig job on the validation data set.\\

The second Pig job:\\
\begin{minipage}{\linewidth}
\begin{lstlisting}
REGISTER [path prefix]/lib/*.jar;
DEFINE Ndcg udf.util.Ndcg('[neural network weights & NDCG cut-off parameter]');
[FIRST TRAINING ITERATION:]
	VALIDATE_SCA = LOAD 'validate_sca[fold number]/*' USING BinStorage();
	VA_BY_QUERY = GROUP VALIDATE_SCA BY $1 PARALLEL [number of available reducers];
	STORE VA_BY_QUERY INTO 'va_by_query-f[fold number]' USING BinStorage();
[SUBSEQUENT TRAINING ITERATIONS:]
	VA_BY_QUERY = LOAD 'va_by_query-f[fold number]/*' USING BinStorage();
NDCG = FOREACH VA_BY_QUERY GENERATE Ndcg(*);
NDCG_GRPD = GROUP NDCG ALL;
AVG_NDCG = FOREACH NDCG_GRPD GENERATE AVG(NDCG);
STORE AVG_NDCG INTO 'avg_ndcg-f[fold number]i[iteration number]';
\end{lstlisting}
\end{minipage}\\

\begin{table}
\centering
\begin{tabular}{p{6cm}p{7cm}}\toprule
UDF & Description \\
\midrule
udf.util.Ndcg() & Calculates \ac{NDCG}@k for a query.\\
\bottomrule
\end{tabular}
\caption{Description of training phase User Defined Functions (Pig job 2)}
\label{tbl:training_udfs_2}
\end{table}

\subsection{Testing}
The testing stage tests the best model found in the training iterations, selected on validation set \ac{NDCG}@k (as calculated in the second Pig job of the training stage), by calculating the \ac{NDCG}@k of this model on the test set.\\

Test stage Pig job:\\
\begin{minipage}{\linewidth}
\begin{lstlisting}
REGISTER [path prefix]/lib/*.jar;
TEST_SCA = LOAD 'test_sca[fold number]/*' USING BinStorage();
TE_BY_QUERY = GROUP TEST_SCA BY $1 PARALLEL [number of available reducers];
DEFINE Ndcg udf.util.Ndcg('[neural network weights & NDCG cut-off parameter]');
NDCG = FOREACH TE_BY_QUERY GENERATE Ndcg(*);
NDCG_GRPD = GROUP NDCG ALL;
AVG_NDCG = FOREACH NDCG_GRPD GENERATE AVG(NDCG);
STORE AVG_NDCG INTO 'avg_ndcg';
\end{lstlisting}
\end{minipage}\\

\section{SmoothRank}
\subsection{Preprocessing}
\subsection{Training}
\subsection{Testing}