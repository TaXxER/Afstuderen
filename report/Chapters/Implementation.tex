This chapter describes implementation details of the Learning-to-Rank algorithm parallel implementations in HDInsight that are either Hadoop, Microsoft Azure, or HDInsight and are not part of the algorithm specification itself. The first section of this chapter will briefly discuss the HDInsight platform, the Hadoop ecosystem components offered by HDInsight and, in this regard, the Hadoop components used for implementation of the algorithms described in Chapter \ref{chap:ltr_methods}.

\section{Architecture}
Ranking models almost without exception consist of a sequence of operations on the input data, that are in most cases repeatedly executed in a series of iterations. Apache Pig will be used to implement the sequence of operation on the input data, because the higher level of abstraction that Apache Pig offers makes it easier to focus solely on the data operations as compared to native Hadoop MapReduce.\\

% TODO: Stuk over werkzaamheden framework uitbreiden: uitlezen resultaten (evaluatieresultaten + doorgeven tussenresultaten (die tweede wellicht later in het document pas introduceren))
In a cross-validation evaluation experiment of a ranking model, the handling of which folds are loaded for training, evaluation and testing is a task that need to be taken care of regardless of the ranking model. Given that most ranking models are of an iterative nature, the task of iteration handling is also a task that need to be done for (most) models. Since these tasks need to be considered for (almost) all ranking models it seems natural to develop a framework that takes care of these tasks. The aim of this framework is to let implementations of ranking models focus solely on implementing the sequential steps of one iteration of the algorithm, while the framework arranges that 1) these sequential steps are performed iteratively and 2) these sequential steps are performed on the multiple training folds of data. This framework that handles folding and iterations will be implemented in Java and will work such that fold- and iteration dependent parts of the Pig code will be generated dynamically by the Java framework after which the Pig job will be sent to the cluster.\\

\subsection{Microsoft Azure HDInsight}
Microsoft offers a scalable and on-demand Hadoop service with HDInsight, that enables Hadoop services for those not able to make the required investments for their own cluster. The latest HDInsight of HDInsight available at the time of writing, HDInsight 3.1, runs the Hortonworks distribution of Hadoop version 2.4. HDInsight 3.1 offers multiple ways of submitting Hadoop jobs to a HDInsight cluster, described in Table \ref{tbl:hdinsight_endpoints}.\\

\begin{table}
\centering
\begin{tabular}{p{4cm}p{2.8cm}p{5.5cm}}\toprule
Job submission method & Type & Description \\
\midrule
Powershell & Powershell scripts & The Azure module for Windows PowerShell enables direct submission of Hadoop jobs through PowerShell cmdlets.\\
C\# API & C\# API & A wrapper API is offered to submit Hadoop MapReduce jobs directly from C\# code.\\
HiveServer/HiveServer2 & REST endpoint & HiveServer and its successor HiveServer 2 are, as its name suggests, REST endpoints that allow remote submission of Hive queries.\\
Oozie & REST endpoint & Apache Oozie is a workflow scheduler to manage Apache Hadoop jobs. Oozie enables users to specify Directed Acyclical Graphs of action, where each action is specified in either MapReduce or Pig.\\
WebHCat/Templeton & REST endpoint & WebHCat, formerly known as Templeton, is a REST API for HCatalog, a table and storage management layer for Hadoop. WebHCat allows users to use either Apache Pig, Apache MapReduce or Apache Hive for data processing.\\	
\bottomrule
\end{tabular}
\caption{HDInsight REST endpoints for job submission}
\label{tbl:hdinsight_endpoints}
\end{table}

Oozie and WebHCat/Templeton are the two methods for job submission in Table \ref{tbl:hdinsight_endpoints} that both 1) support Apache Pig jobs, and 2) Can be used from within Java code. Below the necessary procedures for job submission from Oozie as well as from WebHCat will be sketched.\\

\begin{table}
\centering
\begin{tabular}{p{5cm}p{5cm}}\toprule
Job submission procedure for Apache Oozie & Job submission procedure for WebHCat/Templeton \\
\midrule
1. Let the framework build the Pig job dynamically. & 1. Let the framework build the Pig job dynamically.\\
2. Encapsulate the Pig job in an Oozie workflow. & 2. Submit the Pig job through the WebHCat/Templeton REST API.\\
3. Upload the Oozie workflow to HDFS storage. & \\
4. Execute the Oozie workflow through the Oozie REST API. & \\
\bottomrule
\end{tabular}
\caption{Comparison of Oozie and WebHCat job submission procedures}
\label{tbl:oozie_templeton}
\end{table}

Table \ref{tbl:oozie_templeton} shows how Oozie job submission is more complex then for the case of dynamically generated jobs than WebHCat/Templeton. Oozie is more fitting for static Hadoop jobs that require a workflow consisting of a sequence of Pig and MapReduce jobs mixed together, but is a lesser fit for our situation. Templeton will be used for submission of the Pig jobs, as the HDInsight version that was available at the start of the implementation did not yet support WebHCat.

\subsection{ListNet}
The following sections describe the Pig jobs that form the three independent parts of the ListNet ranking model: 1) Preprocessing, 2) Training (this includes evaluation over the validation set) and 3) Testing (evaluation over the test set). 
\subsubsection{Preprocessing}
The preprocessing phase consists of two separate Pig jobs. The first Pig job determines the minimum and the maximum values per feature in the training set. The second Pig job rescales each feature of the train, validation and test datasets using the following formula for rescaling:
\begin{equation}
x^{'} = \frac{x-min(x)}{max(x)-min(x)}
\end{equation}
This rescaling procedure sets the values of all features to be within range $[0,1]$.\\

The first Pig job:
\begin{lstlisting}
REGISTER [path prefix]/lib/*.jar;
TRAIN = LOAD '[path prefix]/input/[dataset name]/Fold[fold number]/train.txt' USING PigStorage(' ');
TRAIN_STD = FOREACH TRAIN GENERATE flatten(udf.util.ToStandardForm(*));
TRAIN_STD_BY_QUERY = GROUP TRAIN_STD BY $1 PARALLEL [available reducers];
MIN_MAX = FOREACH TRAIN_STD_BY_QUERY GENERATE flatten(udf.util.GetMinMax(*));
MIN_MAX_GRPD = GROUP MIN_MAX ALL;
MIN_MAX_FIN = FOREACH MIN_MAX_GRPD GENERATE flatten(udf.util.CombineMinMax(*));
STORE MIN_MAX_FIN INTO 'minmax[fold number]';
\end{lstlisting}

The minimum and maximum values per feature stored in MIN\_MAX\_FIN can now be read from \ac{HDFS} and used within the Java framework by using the Windows Azure Storage library. The second Pig job uses these minimum and maximum values by parametrising the \ac{UDF} that performs the rescaling transformation, udf.util.ScaleFeatures(), with the minimum and maximum feature values.\\

\begin{table}
\centering
\begin{tabular}{p{5cm}p{8cm}}\toprule
UDF & Description \\
\midrule
udf.util.ToStandardForm() & Transforms the data set into the standard form of relevance label in first column followed by feature values. Strips data of any other columns, if present.\\
udf.util.GetMinMax() & Extracts the minimum and maximum value per feature, for the documents of a single query.\\
udf.util.CombineMinMax() & Combines outputs of the udf.util.GetMinMax() UDF for each query into globally minimum and maximum feature values.\\
\bottomrule
\end{tabular}
\caption{Description of preprocessing User Defined Functions (1/2)}
\label{tbl:preprocessing_udfs_1}
\end{table}

The second Pig job:
\begin{lstlisting}
REGISTER [path prefix]/lib/*.jar;
TRAIN = LOAD '[path prefix]/input/[dataset name]/Fold[fold number]/train.txt' USING PigStorage(' ');
VALIDATE = LOAD '[path prefix]/input/[dataset name]/Fold[fold number]/vali.txt' USING PigStorage(' ');
TEST = LOAD '[path prefix]/input/[dataset name]/Fold[fold number]/test.txt' USING PigStorage(' ');
TRAIN_STD = FOREACH TRAIN GENERATE flatten(udf.util.ToStandardForm(*));
VALIDATE_STD = FOREACH VALIDATE GENERATE flatten(udf.util.ToStandardForm(*));
TEST_STD = FOREACH TEST GENERATE flatten(udf.util.ToStandardForm(*));
DEFINE ScaleFeatures udf.util.ScaleFeatures('[array with minimum and maximum feature values]');
TRAIN_SCA = FOREACH TRAIN_STD GENERATE flatten(ScaleFeatures(*));
VALIDATE_SCA = FOREACH VALIDATE_STD GENERATE flatten(ScaleFeatures(*));
TEST_SCA = FOREACH TEST_STD GENERATE flatten(ScaleFeatures(*));
STORE TRAIN_SCA INTO 'train_sca[fold number]' USING BinStorage();
STORE VALIDATE_SCA INTO 'validate_sca[fold number]' USING BinStorage();
STORE TEST_SCA INTO 'test_sca[fold number]' USING BinStorage();
\end{lstlisting}

\begin{table}
\centering
\begin{tabular}{p{5cm}p{8cm}}\toprule
UDF & Description \\
\midrule
udf.util.ToStandardForm() & See Table \ref{tbl:preprocessing_udfs_1} for description.\\
udf.util.ScaleFeatures() & Uses the minimum and maximum feature values with which it is parametrised perform the following rescaling transformation to the features: $x^{'} = \frac{x-min(x)}{max(x)-min(x)}$.\\
\bottomrule
\end{tabular}
\caption{Description of preprocessing User Defined Functions (2/2)}
\label{tbl:preprocessing_udfs_2}
\end{table}

\subsubsection{Training}
The first Pig job:
\begin{lstlisting}
REGISTER [path prefix]/lib/*.jar;
DEFINE QueryLossGradient udf.listnet.QueryLossGradient('[feature dimensionality of data set]');
DEFINE ExpRelOurScores udf.listnet.ExpRelOurScores('[neural network weights & iteration number]');
[FIRST TRAINING ITERATION:]
	TRAIN_SCA = LOAD 'train_sca[fold number]/*' USING BinStorage();
	TR_BY_QUERY = GROUP TRAIN_SCA BY $1 PARALLEL [number of avaiable reducers];
	TR_EXP_REL_SCORES = FOREACH TR_BY_QUERY GENERATE flatten(ExpRelOurScores(TRAIN_SCA));
	STORE TR_EXP_REL_SCORES INTO 'tr_exp_rel_scores-f[fold number]' USING BinStorage();
[SUBSEQUENT TRAINING ITERATIONS:]
	TR_EXP_REL_SCORES = LOAD 'tr_exp_rel_scores-f[fold number]/*' USING BinStorage();
	TR_EXP_REL_SCORES = FOREACH TR_EXP_REL_SCORES GENERATE flatten(ExpRelOurScores(*)) PARALLEL [number of available reducers];
TR_QUERY_LOSS_GRADIENT = FOREACH TR_EXP_REL_SCORES GENERATE flatten(QueryLossGradient(*)) PARALLEL [number of available reducers];
TR_QUERY_LOSS_GRADIENT_GRPD = GROUP TR_QUERY_LOSS_GRADIENT ALL;
TR_LOSS_GRADIENT = FOREACH TR_QUERY_LOSS_GRADIENT_GRPD GENERATE flatten(udf.listnet.MultiSum(*));
STORE TR_LOSS_GRADIENT INTO 'tr_loss_gradient-f[fold number]i[iteration number]';
\end{lstlisting}

\begin{table}
\centering
\begin{tabular}{p{5cm}p{8cm}}\toprule
UDF & Description \\
\midrule
udf.listnet.QueryLossGradient() & Calculates the Cross Entropy loss for a query and calculates the gradients per feature based on this query.\\
udf.listnet.ExpRelOurScores() & Calculates the predicted relevance label of a query based on the current model weights and transforms this following the transformation $x -> e^{x}$. In case the current iteration is the first iteration, the same transformation is applied to the ground truth relevance label.\\
udf.listnet.MultiSum() & Calculates aggregated loss and feature gradients by summing the per-query losses and per-query feature gradients.\\
\bottomrule
\end{tabular}
\caption{Description of training User Defined Functions (1/2)}
\label{tbl:training_udfs_1}
\end{table}

The second Pig job of the training stage tests the performance of the model weights that were trained in the first Pig job on the validation data set.
The second Pig job:
\begin{lstlisting}
REGISTER [path prefix]/lib/*.jar;
DEFINE Ndcg udf.util.Ndcg('[neural network weights & NDCG cut-off parameter]');
[FIRST TRAINING ITERATION:]
	VALIDATE_SCA = LOAD 'validate_sca[fold number]/*' USING BinStorage();
	VA_BY_QUERY = GROUP VALIDATE_SCA BY $1 PARALLEL [number of available reducers];
	STORE VA_BY_QUERY INTO 'va_by_query-f[fold number]' USING BinStorage();
[SUBSEQUENT TRAINING ITERATIONS:]
	VA_BY_QUERY = LOAD 'va_by_query-f[fold number]/*' USING BinStorage();
NDCG = FOREACH VA_BY_QUERY GENERATE Ndcg(*);
NDCG_GRPD = GROUP NDCG ALL;
AVG_NDCG = FOREACH NDCG_GRPD GENERATE AVG(NDCG);
STORE AVG_NDCG INTO 'avg_ndcg-f[fold number]i[iteration number]';
\end{lstlisting}
\begin{table}
\centering
\begin{tabular}{p{5cm}p{8cm}}\toprule
UDF & Description \\
\midrule
udf.util.Ndcg() & Calculates \ac{nDCG}@k for a query.\\
\bottomrule
\end{tabular}
\caption{Description of training User Defined Functions (2/2)}
\label{tbl:training_udfs_2}
\end{table}

\subsubsection{Testing}
Pig Job:
\begin{lstlisting}
REGISTER [path prefix]/lib/*.jar;
TEST_SCA = LOAD 'test_sca[fold number]/*' USING BinStorage();
TE_BY_QUERY = GROUP TEST_SCA BY $1 PARALLEL [number of available reducers];
DEFINE Ndcg udf.util.Ndcg('[neural network weights & NDCG cut-off parameter]');
NDCG = FOREACH TE_BY_QUERY GENERATE Ndcg(*);
NDCG_GRPD = GROUP NDCG ALL;
AVG_NDCG = FOREACH NDCG_GRPD GENERATE AVG(NDCG);
STORE AVG_NDCG INTO 'avg_ndcg';
\end{lstlisting}